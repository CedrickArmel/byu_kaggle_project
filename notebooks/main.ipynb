{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc6ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from torchinfo import summary\n",
    "from app.config import root_dir\n",
    "from app.metrics import BYUFbeta\n",
    "from app.metrics.metrics import get_topk_by_id, thresholder, filter_negatives\n",
    "from app.models.lightning import Net\n",
    "from app.models import LNet\n",
    "from app.utils import get_data, get_data_loader\n",
    "from app.processings.post_processing import get_output_size, reconstruct, simple_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490d5ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.typing import NDArray\n",
    "from scipy.spatial import KDTree\n",
    "from torchmetrics.utilities import dim_zero_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0f7c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OmegaConf.register_new_resolver(\"root_dir\", resolver=root_dir, replace=True)\n",
    "OmegaConf.register_new_resolver(\"eval\", resolver=eval, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27ea36",
   "metadata": {},
   "source": [
    "os.environ[\"ISTPUVM\"] = \"1\"\n",
    "os.environ[\"PJRT_DEVICE\"] = \"CPU\"\n",
    "os.environ[\"PT_XLA_DEBUG_LEVEL\"] = \"1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"TPU_ACCELERATOR_TYPE\"] = \"v3-8\"\n",
    "os.environ[\"TPU_CHIPS_PER_HOST_BOUNDS\"] = \"2,2,1\"\n",
    "os.environ[\"TPU_HOST_BOUNDS\"] = \"1,1,1\"\n",
    "os.environ[\"TPU_RUNTIME_METRICS_PORTS\"] = \"8431,8432,8433,8434\"\n",
    "os.environ[\"TPU_SKIP_MDS_QUERY\"] = \"1\"\n",
    "os.environ[\"TPU_WORKER_HOSTNAMES\"] = \"localhost\"\n",
    "os.environ[\"TPU_WORKER_ID\"] = \"0\"\n",
    "os.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db72768",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"../src/app/config/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0a76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = get_data(cfg, mode=\"fit\")\n",
    "train_loader = get_data_loader(cfg, train_df, mode=\"train\")\n",
    "val_loader = get_data_loader(cfg, val_df, mode=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92f733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1 = torch.load(\"/kaggle/working/resnet50/seed_4294967295/fold0/20250513193109/val_epoch_7_end_step384_rank1.pt\")\n",
    "preds2 = torch.load(\"/kaggle/working/resnet50/seed_4294967295/fold0/20250513193056/val_epoch_7_end_step384_rank0.pt\")\n",
    "preds = torch.cat([preds1, preds2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "040411de",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.from_numpy(val_df[[\"z\", \"y\", \"x\", \"id\", \"vxs\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad3dcd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk  = get_topk_by_id(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aeda759",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut_preds, candidates, ntargets, ptargets = thresholder(0.998, topk, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620b1b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = BYUFbeta(cfg, compute_on_cpu=True, dist_sync_on_step=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6b3a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zyxic = torch.load(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e226b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = torch.from_numpy(val_df[val_df.id.isin(np.unique(zyxic[:, 3]))][[\"z\", \"y\", \"x\", \"id\", \"vxs\"]].copy().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a810e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = metric(zyxic, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d483f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb129882",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = torch.load(\"/kaggle/working/logits.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17a7b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_it = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f9cc4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(tr_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24f2b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"logits\"] = torch.from_numpy(test_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd9e8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {k:v.to(\"cuda:0\") if isinstance(v, torch.Tensor) else v for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "365302ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e47cf8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_output = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83a5eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = net_output[\"logits\"].device\n",
    "new_size = torch.tensor(cfg.new_size, device=net_output[\"logits\"].device)\n",
    "roi_size = torch.tensor(cfg.roi_size, device=net_output[\"logits\"].device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "193b6ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img: \"torch.Tensor\" = net_output[\"logits\"].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5868e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations: \"torch.Tensor\" = net_output[\"location\"]\n",
    "scales: \"torch.Tensor\" = net_output[\"scale\"]\n",
    "tomo_ids: \"torch.Tensor\" = torch.tensor(net_output[\"id\"], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f97c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = F.interpolate(\n",
    "    img,\n",
    "    size=roi_size.tolist(),\n",
    "    mode=\"trilinear\",\n",
    "    align_corners=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b29e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_size = get_output_size(img, locations, roi_size, device)\n",
    "rec_img = reconstruct(\n",
    "    img=img,\n",
    "    locations=locations,\n",
    "    out_size=out_size,\n",
    "    crop_size=roi_size,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "161ddf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor(rec_img.shape[-3:], device=device)\n",
    "delta = (s - new_size) // 2  # delta to remove padding added during transforms\n",
    "dz, dy, dx = delta.tolist()\n",
    "nz, ny, nx = new_size.tolist()\n",
    "\n",
    "rec_img = rec_img[:, :, dz : nz + dz, dy : ny + dy, dx : nx + dx]\n",
    "\n",
    "rec_img = F.interpolate(\n",
    "    rec_img,\n",
    "    size=[d // 2 for d in new_size.tolist()],\n",
    "    mode=\"trilinear\",\n",
    "    align_corners=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fab87893",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds: \"torch.Tensor\" = rec_img.softmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a8e33fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1270, device='cuda:0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:, 0].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55cf0213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8122, device='cuda:0')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:, 0].quantile(q=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1094c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds0 = preds[:, 0, :][None,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "776d1053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5334e-11, device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:, 0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "658186ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms: \"torch.Tensor\" = simple_nms(preds, nms_radius=100)  # (1,B, D, H, W)\n",
    "nms = nms.squeeze(dim=0)  # (B, D, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f97068",
   "metadata": {},
   "outputs": [],
   "source": [
    "nms.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c82d8969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9918, 0.9989, 0.9984, 0.9913, 0.9997, 0.9918, 0.9900, 0.9958, 0.9979,\n",
       "        0.9990, 0.9998, 0.9998, 0.9999, 0.9986, 1.0000, 0.9993, 0.9975, 1.0000,\n",
       "        0.9960, 0.9985, 0.9990, 0.9989, 0.9995, 0.9993, 0.9996, 0.9921, 0.9991,\n",
       "        0.9932, 0.9999, 0.9982, 0.9904, 0.9940, 0.9990, 0.9999, 0.9967, 0.9996,\n",
       "        0.9995, 0.9981, 0.9987, 0.9943, 0.9952, 0.9988, 0.9968, 0.9992],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nms[nms>0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3326da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_pipeline(\n",
    "    cfg: \"DictConfig\", net_output: \"dict[str, Any]\"\n",
    ") -> \"torch.Tensor\":\n",
    "    \"\"\"Post-process the output of the model to get the final coordinates and confidence scores.\n",
    "    Args:\n",
    "        cfg (DictConfig): Configuration object containing project's parameters.\n",
    "        net_output (dict): The output of the model.\n",
    "    Returns:\n",
    "        torch.Tensor: The final coordinates and confidence scores.\n",
    "    \"\"\"\n",
    "    device = net_output[\"logits\"].device\n",
    "    new_size = torch.tensor(cfg.new_size, device=net_output[\"logits\"].device)\n",
    "    roi_size = torch.tensor(cfg.roi_size, device=net_output[\"logits\"].device)\n",
    "\n",
    "    img: \"torch.Tensor\" = net_output[\"logits\"].detach()\n",
    "\n",
    "    locations: \"torch.Tensor\" = net_output[\"location\"]\n",
    "    scales: \"torch.Tensor\" = net_output[\"scale\"]\n",
    "    tomo_ids: \"torch.Tensor\" = torch.tensor(net_output[\"id\"], device=device)\n",
    "\n",
    "    img = F.interpolate(\n",
    "        img,\n",
    "        size=roi_size.tolist(),\n",
    "        mode=\"trilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    out_size = get_output_size(img, locations, roi_size, device)\n",
    "    rec_img = reconstruct(\n",
    "        img=img,\n",
    "        locations=locations,\n",
    "        out_size=out_size,\n",
    "        crop_size=roi_size,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    s = torch.tensor(rec_img.shape[-3:], device=device)\n",
    "    delta = (s - new_size) // 2  # delta to remove padding added during transforms\n",
    "    dz, dy, dx = delta.tolist()\n",
    "    nz, ny, nx = new_size.tolist()\n",
    "\n",
    "    rec_img = rec_img[:, :, dz : nz + dz, dy : ny + dy, dx : nx + dx]\n",
    "\n",
    "    rec_img = F.interpolate(\n",
    "        rec_img,\n",
    "        size=[d // 2 for d in new_size.tolist()],\n",
    "        mode=\"trilinear\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    preds: \"torch.Tensor\" = rec_img.softmax(1)\n",
    "    preds = preds[:, 0, :][None,]\n",
    "\n",
    "    nms: \"torch.Tensor\" = simple_nms(preds, nms_radius=cfg.nms_radius)  # (1,B, D, H, W)\n",
    "    nms = nms.squeeze(dim=0)  # (B, D, H, W)\n",
    "\n",
    "    flat_nms = nms.reshape(nms.shape[0], -1)  # (B, D*H*W)\n",
    "    conf, indices = torch.topk(flat_nms, k=cfg.topk, dim=1)\n",
    "    zyx = torch.stack(torch.unravel_index(indices, nms.shape[-3:]), dim=-1)  # (B, K, 3)\n",
    "\n",
    "    b = torch.arange(zyx.shape[0], device=device).unsqueeze(1)\n",
    "    ids = torch.unique(tomo_ids.reshape(zyx.shape[0], -1), dim=1).expand(\n",
    "        zyx.shape[0], cfg.topk\n",
    "    )\n",
    "\n",
    "    zyx = ((zyx * 2) / scales[b]).round().to(torch.int)\n",
    "    conf = conf.to(torch.float32)\n",
    "\n",
    "    ids = ids.reshape(-1, 1)\n",
    "    conf = conf.reshape(-1, 1)\n",
    "    zyx = zyx.reshape(-1, 3)\n",
    "\n",
    "    output: \"torch.Tensor\" = torch.cat([zyx, ids, conf], dim=1)\n",
    "    return output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byu_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
